{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTWyrvqTYUKLZJ0HhM2q0s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grfaith/AmericanStories/blob/main/Finding_explore_kw_proximity_hits_in_AS_string_word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY00mYewtFuU",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "###Installs\n",
        "\n",
        "!pip install datasets\n",
        "!pip install ipympl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is code for looking at a range of years in the American Stories data and finding articles which appear with the string 'explor' and saving their information to disk."
      ],
      "metadata": {
        "id": "ynmUlyRjtbwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import json\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import tqdm as tq\n",
        "from google.colab import files\n",
        "import re\n",
        "\n",
        "kw_distance = 150\n"
      ],
      "metadata": {
        "id": "Fy1ZCAu_twkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full ChronAm extends back to 1774 (I think). Previous searches have returnedo hits\n",
        "start_year = 1910 #This is start-year inclusive\n",
        "\n",
        "# Complete dataset runs to 1940 inclusive, but this particular implementation runs out of space about 1905, so I'm breaking it into chunks\n",
        "end_year = 1940 #This is end-year exclusive (I think)"
      ],
      "metadata": {
        "id": "eXGE89OnTDin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Cell for loading files from local drive\n",
        "kw_file = files.upload()\n",
        "\n",
        "# Specify custom column names\n",
        "column_names = [\"kword\", \"kwyear\", \"kwtype\"]\n",
        "\n",
        "# Read the uploaded CSV file into a DataFrame with custom column names\n",
        "for fn in kw_file.keys():\n",
        "    kw_df = pd.read_csv(fn, names=column_names, header=None)\n",
        "\n",
        "# Display information about the uploaded file\n",
        "for fn in kw_file.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "          name=fn, length=len(kw_file[fn])))\n",
        "\n"
      ],
      "metadata": {
        "id": "IudtCh2We58L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining function to load dataset\n",
        "\n",
        "def load_text_dataset(dataset_year_str):\n",
        "    \"\"\"\n",
        "    This function pulls a dataset of a specific year from the HuggingFace Hub.\n",
        "\n",
        "    Parameters:\n",
        "        dataset_year (int): The year of the dataset to be pulled..\n",
        "\n",
        "    Returns:\n",
        "        dataset_article_level: dataset for appropriate year\n",
        "    \"\"\"\n",
        "    # Download data for the dataset year at the associated article level (Default)\n",
        "    # dataset = load_dataset(\"dell-research-harvard/AmericanStories\", \"subset_years\", year_list=[dataset_year])\n",
        "\n",
        "    # now let's load our data, we have to specify the huggingface location of our\n",
        "    # data, the fact that we want to have a subset of years, and our desired years\n",
        "    dataset_article_level=load_dataset(\"dell-research-harvard/AmericanStories\",\n",
        "                                      \"subset_years\",\n",
        "                                       year_list=[dataset_year_str],\n",
        "                                       trust_remote_code=True\n",
        "                                       )\n",
        "\n",
        "    return dataset_article_level"
      ],
      "metadata": {
        "id": "Ek6QpIYKyGpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Function to filter kw data in use based on years of discovery in kw file.\n",
        "\n",
        "def get_kw(dataset_year_str):\n",
        "    \"\"\"\n",
        "    This function loads a CSV file to create a DataFrame and filters out keywords where the second column is less than 1774\n",
        "    Parameters:\n",
        "        kw_file loaded from prompt above\n",
        "    Returns:\n",
        "        pandas.DataFrame: The filtered Data\n",
        "    \"\"\"\n",
        "    # Convert dataset_year to integer\n",
        "    dataset_year = int(dataset_year_str)\n",
        "\n",
        "    # Filter the rows based on the condition\n",
        "    kw_df_filter = kw_df[kw_df['kwyear'] <= dataset_year]\n",
        "\n",
        "    # print(kw_df_filter)\n",
        "\n",
        "    return kw_df_filter\n",
        "\n"
      ],
      "metadata": {
        "id": "-SvYzj3t89IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_kw(dataset_year_str, kw_df_filter, dataset_article_level):\n",
        "    \"\"\"\n",
        "    This function processes words in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "        kw_df_filter (pandas.DataFrame): The DataFrame containing keywords\n",
        "        dataset_article (DatasetDict): A dictionary-like object containing datasets for different years.\n",
        "\n",
        "    Returns:\n",
        "        dataset_year_hits (DataFrame or None): A DataFrame containing results if found, or None if no results were found.\n",
        "    \"\"\"\n",
        "    print (\"Searching within \", dataset_year_str)\n",
        "\n",
        "    # Creating an empty dataframe\n",
        "    current_year_df = pd.DataFrame()\n",
        "\n",
        "    for index, row in kw_df_filter.iterrows():\n",
        "        explore_kw = row.iloc[0]\n",
        "        kw_type = row.iloc[2]\n",
        "        # print(explore_kw, kw_type)\n",
        "        result_df = kw_pair_search(dataset_article_level, dataset_year_str, explore_kw, kw_distance, kw_type)\n",
        "        # Concatenate the single search result onto the results DataFrame\n",
        "        current_year_df = pd.concat([current_year_df, result_df], ignore_index=True)\n",
        "\n",
        "    return current_year_df\n"
      ],
      "metadata": {
        "id": "Mf7CjY-AznRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## key word search within articles to find keywords with kw_distance of the string 'explor'\n",
        "\n",
        "def kw_pair_search(dataset_article, dataset_year, explor_kw, kw_distance, kw_type):\n",
        "    \"\"\"\n",
        "    This function searches through the dataset, by kw, to look for matching articles.\n",
        "\n",
        "    Parameters:\n",
        "        dataset_article (DatasetDict): A dictionary-like object containing datasets for different years.\n",
        "        dataset_year (int): The year of the dataset.\n",
        "        explor_kw (str): The keyword to search for.\n",
        "        kw_distance (int): The maximum distance allowed between occurrences of the two keywords.\n",
        "\n",
        "    Returns:\n",
        "        df_of_articles_containing_two_words (DataFrame): A DataFrame containing article IDs and article texts of articles containing both keywords within the specified distance.\n",
        "    \"\"\"\n",
        "    # Access the dataset for the specific year\n",
        "    year_dataset = dataset_article[dataset_year]\n",
        "\n",
        "    # Access the 'raw_data_string' column\n",
        "    articles = year_dataset['article']\n",
        "\n",
        "    # Create empty list to store matching articles\n",
        "    articles_containing_two_words = []\n",
        "\n",
        "    for article_n, article_text in enumerate(articles):\n",
        "        article_text = article_text.lower()\n",
        "        if \"explor\" in article_text and explor_kw in article_text:\n",
        "            # print (\"We have a hit at\", article_n)\n",
        "\n",
        "            # Define the pattern to search for \"explor\" within words\n",
        "            pattern_explor = re.compile(r'\\b\\w*explor\\w*\\b')\n",
        "\n",
        "            # Find indices of matches in the article text\n",
        "            explor_indices = [match.start() for match in pattern_explor.finditer(article_text)]\n",
        "\n",
        "            # Determine if the search needs to be on a string or on a word\n",
        "\n",
        "            if kw_type == \"string\":\n",
        "                # Define the pattern to search for the value of 'explor_kw' within words\n",
        "                pattern_kw = re.compile(r'\\b\\w*' + re.escape(explor_kw) + r'\\w*\\b', flags=re.IGNORECASE)\n",
        "            elif kw_type == \"word\":\n",
        "                # Define the pattern to search for the exact value of 'explor_kw' as a whole word\n",
        "                pattern_kw = re.compile(r'\\b' + re.escape(explor_kw) + r'\\b', flags=re.IGNORECASE)\n",
        "            else:\n",
        "                # Handle the case when kw_type is neither \"string\" nor \"word\"\n",
        "                raise ValueError(\"Invalid kw_type. Must be either 'string' or 'word'.\")\n",
        "\n",
        "\n",
        "            # Find indices of matches in the article text\n",
        "            kw_indices = [match.start() for match in pattern_kw.finditer(article_text)]\n",
        "            #print (kw_indices)\n",
        "            #input (\"Press Enter to continue\")\n",
        "\n",
        "            # Check if there are any pairs of indices within the specified distance\n",
        "            for explor_index in explor_indices:\n",
        "                for kw_index in kw_indices:\n",
        "                    if abs(explor_index - kw_index) <= kw_distance:\n",
        "                        # print (\"SUCCESS!!\", dataset_year, article_n)\n",
        "                        # Append the matching article information to the list\n",
        "                        articles_containing_two_words.append({\n",
        "                            'article_year': dataset_year,\n",
        "                            'row_number': article_n,\n",
        "                            'article_ID': dataset_article[dataset_year][article_n][\"article_id\"],\n",
        "                            'newspaper_name': dataset_article[dataset_year][article_n][\"newspaper_name\"],\n",
        "                            'edition': dataset_article[dataset_year][article_n][\"edition\"],\n",
        "                            'date': dataset_article[dataset_year][article_n][\"date\"],\n",
        "                            'page': dataset_article[dataset_year][article_n][\"page\"],\n",
        "                            'headline': dataset_article[dataset_year][article_n][\"headline\"],\n",
        "                            'byline': dataset_article[dataset_year][article_n][\"byline\"],\n",
        "                            'article': dataset_article[dataset_year][article_n][\"article\"],\n",
        "                            'keyword_hit': explor_kw,\n",
        "                            'kw_index': kw_index,\n",
        "                            'explor_index': explor_index,\n",
        "                        })\n",
        "                        # Once a matching pair is found, break out of the loop\n",
        "                        # break\n",
        "                    else:\n",
        "                        continue\n",
        "\n",
        "    # Convert the list of dictionaries to a DataFrame\n",
        "    df_of_articles_containing_two_words = pd.DataFrame(articles_containing_two_words)\n",
        "    return df_of_articles_containing_two_words\n"
      ],
      "metadata": {
        "id": "mVewWmA8BqHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame()\n",
        "\n",
        "for loop_year in range(start_year, end_year):\n",
        "    dataset_year_str = str(loop_year)\n",
        "    try:\n",
        "        # Load dataset for current loop_year\n",
        "        dataset_article_level = load_text_dataset(dataset_year_str)\n",
        "\n",
        "        # Get valid keyword filters for current year\n",
        "        kw_df_filter = get_kw(loop_year)\n",
        "        # print (\"Processing year\", dataset_year_str)\n",
        "\n",
        "        # Process keyword filters and dataset for current loop year to get hits\n",
        "        year_search_result = process_kw(dataset_year_str,kw_df_filter, dataset_article_level)\n",
        "\n",
        "        # if not year_search_result.empty:\n",
        "        #   print(\"Found: \", year_search_result)\n",
        "        # else:\n",
        "        #   print(\"No results found for \", dataset_year_str)\n",
        "\n",
        "        # Concatenate the single search result onto the results DataFrame\n",
        "        results = pd.concat([results, year_search_result])\n",
        "\n",
        "    except ValueError:\n",
        "        print(f\"Dataset empty for {dataset_year_str}. Moving to the next year.\")\n",
        "        continue\n",
        "\n",
        "results = results.reset_index(drop=True)\n",
        "results.to_csv('AS_Explor_KW_Hits_Prox_SW_Part_3_In Fxn.csv', index=False)\n",
        "files.download(\"AS_Explor_KW_Hits_Prox_SW_Part_3_In Fxn.csv\")\n",
        "print(\"Finished\")\n"
      ],
      "metadata": {
        "id": "aUp2-Y38I1S7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell if you have to interrupt the above loop to save progress.\n",
        "#  Update file names as appropriate.\n",
        "\n",
        "\n",
        "results = results.reset_index(drop=True)\n",
        "results.to_csv('AS_Explor_KW_Hits_Prox_SW_Part_3.csv', index=False)\n",
        "files.download(\"AS_Explor_KW_Hits_Prox_SW_Part_3.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vcDisoRbtac4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Now save output file to local disk\")\n",
        "input(\"Press Enter to continue...\")\n"
      ],
      "metadata": {
        "id": "--y_oVw3SDw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SOLVENT FRONT**"
      ],
      "metadata": {
        "id": "C4VnKX6vPPzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(results.info)\n"
      ],
      "metadata": {
        "id": "NbaYEb_oUdKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's start with deciding which years we want data for\n",
        "scan_level_desired_years = [\"1900\",]\n",
        "\n",
        "# now let's load our data, we have to specify the huggingface location of our\n",
        "# data, the fact that we want to have a subset of years, and our desired years\n",
        "dataset_scan_level=load_dataset(\"dell-research-harvard/AmericanStories\",\n",
        "                                \"subset_years_content_regions\",\n",
        "                                year_list=scan_level_desired_years\n",
        "                                )"
      ],
      "metadata": {
        "id": "uhbDJhIIPkFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_article_level['1900'][377385][\"article\"])"
      ],
      "metadata": {
        "id": "omn6rKx4POKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2S0F_5I0PN7N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}